{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b87d4a55",
   "metadata": {},
   "source": [
    "## Predicting Default on Payments of Credit Card Clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64a4c6e",
   "metadata": {},
   "source": [
    "# 3. Model Training & Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fa1f87",
   "metadata": {},
   "source": [
    "Within the ML Analytics Recruitment Challenge, the goal of this notebook is to train machine learning models to predict whether a credit card client will default in the following month and evaluate the performance of these models.\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "### Main Insights:\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    Write stuff.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    Write stuff.\n",
    "</div>\n",
    "\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd1dd97",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fda9460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "from typing import Dict, List\n",
    "\n",
    "seed = 17\n",
    "np.random.seed(seed)\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedca013",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489176b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8706a731",
   "metadata": {},
   "source": [
    "#### Data processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dda49720",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    \"\"\"\n",
    "    Class that aggregates a set of functions for loading, cleaning, feature engineering, encoding,\n",
    "    and normalize data, among others, with the goal of preparing the data to be feed into a model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mappings : Dict<str, Dict>\n",
    "        Dictionary that specifies the mapping of categorical features. The keys in the dictionary \n",
    "        are the names of the columns that represent the categorical features, and the values are \n",
    "        also dictionaries that specify the mapping of the categorical values. \n",
    "    \n",
    "    seed : int, optional\n",
    "        Integer used to control the random state, default is 17. \n",
    "        \n",
    "    target_col_name : str, optional\n",
    "        Name of the target variable, default is 'target'.\n",
    "        \n",
    "    val_size : float, optional\n",
    "        Represents the propotion of the train dataset to include in the validation split, by default\n",
    "        is 0.2.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        mappings: Dict,\n",
    "        seed: int = 17,\n",
    "        target_col_name: str = \"target\",\n",
    "        val_size: float = 0.2\n",
    "    ):\n",
    "        self.target_name = target_col_name\n",
    "        \n",
    "        self._mappings = mappings\n",
    "        self._seed = seed\n",
    "        self._val_size = val_size\n",
    "        \n",
    "        \n",
    "        # Variables to be initialized later:\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_val = None\n",
    "        self.y_val = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "        self.standard_scaler = None\n",
    "    \n",
    "    \n",
    "    def load_train_data(self, file_directory: str):\n",
    "        \"\"\"Loads the train data from a given directory.\"\"\"\n",
    "        self.train_data = pd.read_csv(file_directory)\n",
    "        self._initial_dataset_uniformization(dataset_type=\"train\")\n",
    "    \n",
    "    def load_test_data(self, file_directory: str):\n",
    "        \"\"\"Loads the test data from a given directory.\"\"\"\n",
    "        self.test_data = pd.read_csv(file_directory)\n",
    "        self._initial_dataset_uniformization(dataset_type=\"test\")\n",
    "    \n",
    "    def split_data(self):\n",
    "        \"\"\"Splits the train set into train and validation sets, and decomposes all sets into X and y.\"\"\"\n",
    "        self.X_train = self.train_data.iloc[:, :-1]\n",
    "        self.y_train = self.train_data.iloc[:, -1]\n",
    "        \n",
    "        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(\n",
    "            self.X_train, \n",
    "            self.y_train, \n",
    "            test_size=self._val_size, \n",
    "            shuffle=True,\n",
    "            random_state=self._seed,\n",
    "            stratify=self.y_train\n",
    "        )\n",
    "        \n",
    "        self.val_data = pd.concat([self.X_val, self.y_val], axis=1)\n",
    "        \n",
    "        self.X_test = self.test_data.iloc[:, :-1]\n",
    "        self.y_test = self.test_data.iloc[:, -1]\n",
    "        \n",
    "    def treat_categorical_variables(self, drop_original_vars: bool = True):\n",
    "        \"\"\"Reencodes of 'education' variable and creation of flags for clients who are male, married, or single.\"\"\"\n",
    "        self.X_train = self._treat_categorical_variables(self.X_train, drop_original_vars)\n",
    "        self.X_val = self._treat_categorical_variables(self.X_val, drop_original_vars)\n",
    "        self.X_test = self._treat_categorical_variables(self.X_test, drop_original_vars)\n",
    "        \n",
    "    def feature_engineering(\n",
    "        self, \n",
    "        calculate_bill_to_limit_bal_ratio: bool = False,\n",
    "        calculate_pay_to_bill_ratio: bool = False,\n",
    "        calculate_num_negative_bill_statements: bool = False,\n",
    "        calculate_payment_delays: bool = False,\n",
    "        calculate_payment_change_rate: bool = False,\n",
    "        calculate_bill_change_rate: bool = False,\n",
    "        calculate_total_payment: bool = False,\n",
    "        list_vars_to_drop: List = None\n",
    "    ):\n",
    "        \"\"\" \"\"\"\n",
    "        self._calculate_bill_to_limit_bal_ratio = calculate_bill_to_limit_bal_ratio\n",
    "        self._calculate_pay_to_bill_ratio = calculate_pay_to_bill_ratio\n",
    "        self._calculate_num_negative_bill_statements = calculate_num_negative_bill_statements\n",
    "        self._calculate_payment_delays = calculate_payment_delays\n",
    "        self._calculate_payment_change_rate = calculate_payment_change_rate\n",
    "        self._calculate_bill_change_rate = calculate_bill_change_rate\n",
    "        self._calculate_total_payment = calculate_total_payment\n",
    "        self._list_vars_to_drop = list_vars_to_drop\n",
    "        \n",
    "        # Perform feature engineering:\n",
    "        self.X_train = self._feature_engineering(self.X_train)\n",
    "        self.X_val = self._feature_engineering(self.X_val)\n",
    "        self.X_test = self._feature_engineering(self.X_test)\n",
    "        \n",
    "    def perform_oversampling(self):\n",
    "        \"\"\" \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def treat_outliers(self):\n",
    "        \"\"\"Filters outliers according to IQR criteria and replaces the values by Q1 or Q3.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def standardize_data(self):\n",
    "        \"\"\"Standardize features by removing the mean and scaling to unit variance.\"\"\"\n",
    "        self.standard_scaler = StandardScaler()\n",
    "        \n",
    "        self.X_train = self.standard_scaler.fit_transform(self.X_train)\n",
    "        self.X_val = self.standard_scaler.transform(self.X_val)\n",
    "        self.X_test = self.standard_scaler.transform(self.X_test)\n",
    "    \n",
    "    def print_dataset_stats(self, normalize: bool = False):\n",
    "        \"\"\"Prints number of samples per set and target classes proportion.\"\"\"\n",
    "        print(f\"Train dataset: {len(self.X_train)} samples, with the target classes as follow:\")\n",
    "        display(self.train_data.target.value_counts(normalize=normalize))\n",
    "        \n",
    "        print(f\"Val dataset: {len(self.X_val)} samples, with the target classes as follow:\")\n",
    "        display(self.val_data.target.value_counts(normalize=normalize))\n",
    "        \n",
    "        print(f\"Test dataset: {len(self.X_test)} samples, with the target classes as follow:\")\n",
    "        display(self.test_data.target.value_counts(normalize=normalize))\n",
    "        \n",
    "    def _map_values(self, col, mapping):\n",
    "        \"\"\"Function to encode a column in a dataframe.\"\"\"\n",
    "        return col.map(mapping)\n",
    "    \n",
    "    def _initial_dataset_uniformization(self, dataset_type: str):\n",
    "        \"\"\"Performs initial steps in the dataset such as renaming columns and removing 'id' column.\"\"\"\n",
    "        rename_cols_map = {\"default.payment.next.month\": \"target\", \"PAY_0\": \"PAY_1\"}\n",
    "        \n",
    "        if dataset_type == \"train\":\n",
    "            self.train_data.rename(columns=rename_cols_map, inplace=True)\n",
    "            self.train_data.columns = [col.lower() for col in self.train_data.columns]\n",
    "            self.train_data.drop(columns=[\"id\"], axis=1, inplace=True)\n",
    "        elif dataset_type == \"test\":\n",
    "            self.test_data.rename(columns=rename_cols_map, inplace=True)\n",
    "            self.test_data.columns = [col.lower() for col in self.test_data.columns]\n",
    "            self.test_data.drop(columns=[\"id\"], axis=1, inplace=True)\n",
    "        else:\n",
    "            raise ValueError(f\"dataset_type arg must be 'train' or 'test', got {dataset_type} instead.\")\n",
    "            \n",
    "    def _treat_categorical_variables(self, data: pd.DataFrame, drop_original_vars: bool = True):\n",
    "        \"\"\"Internal function that reencodes of 'education' variable and creation of flags for clients who are male,\n",
    "        married, or single.\"\"\"\n",
    "        assert \"education\" in self._mappings, \"There is no mapping to reencode 'education' variable.\"\n",
    "        \n",
    "        data.education = self._map_values(data.education, self._mappings.get(\"education\"))\n",
    "        \n",
    "        data[\"is_male\"] = np.where(data.sex == 1, 1, 0)\n",
    "        data[\"is_married\"] = np.where(data.marriage == 1, 1, 0)\n",
    "        data[\"is_single\"] = np.where(data.marriage == 2, 1, 0)\n",
    "        \n",
    "        if drop_original_vars:\n",
    "            data.drop([\"sex\", \"marriage\"], axis=1, inplace=True)\n",
    "                    \n",
    "        return data\n",
    "            \n",
    "    def _feature_engineering(self, data: pd.DataFrame):\n",
    "        \"\"\" \"\"\"\n",
    "        def avoid_zero_division(row, pay_amt, bill_amt):\n",
    "            \"\"\"\"Util function that returns the pay_amtX when bill_amtX is equal to zero.\"\"\"\n",
    "            if row[bill_amt] == 0:\n",
    "                # If pay_amt is positive, it means the client has overpaid:\n",
    "                return -row[pay_amt]\n",
    "        \n",
    "            return 0.0 if row[pay_amt] == 0 else row[pay_amt] / row[bill_amt]\n",
    "        \n",
    "        def calculate_change_rate(row, col_amt1, col_amt2):\n",
    "            \"\"\"Calculates the change rate (pay_amt or bill_amt) between two consecutive months.\"\"\"\n",
    "            if row[col_amt1] == 0:\n",
    "                return 0.0\n",
    "            else:\n",
    "                return (row[col_amt2] - row[col_amt1] / row[col_amt1])\n",
    "\n",
    "        if self._calculate_bill_to_limit_bal_ratio:\n",
    "            data[\"bill_amt1_limit_bal_ratio\"] = data.bill_amt1 / data.limit_bal\n",
    "            data[\"bill_amt2_limit_bal_ratio\"] = data.bill_amt2 / data.limit_bal\n",
    "            data[\"bill_amt3_limit_bal_ratio\"] = data.bill_amt3 / data.limit_bal\n",
    "            data[\"bill_amt4_limit_bal_ratio\"] = data.bill_amt4 / data.limit_bal\n",
    "            data[\"bill_amt5_limit_bal_ratio\"] = data.bill_amt5 / data.limit_bal\n",
    "            data[\"bill_amt6_limit_bal_ratio\"] = data.bill_amt6 / data.limit_bal\n",
    "        \n",
    "        if self._calculate_pay_to_bill_ratio:\n",
    "            data[\"pay_amt1_bill_amt1_ratio\"] = data.apply(lambda x: avoid_zero_division(x, \"pay_amt1\", \"bill_amt1\"), axis=1)\n",
    "            data[\"pay_amt2_bill_amt2_ratio\"] = data.apply(lambda x: avoid_zero_division(x, \"pay_amt2\", \"bill_amt2\"), axis=1)\n",
    "            data[\"pay_amt3_bill_amt3_ratio\"] = data.apply(lambda x: avoid_zero_division(x, \"pay_amt3\", \"bill_amt3\"), axis=1)\n",
    "            data[\"pay_amt4_bill_amt4_ratio\"] = data.apply(lambda x: avoid_zero_division(x, \"pay_amt4\", \"bill_amt4\"), axis=1)\n",
    "            data[\"pay_amt5_bill_amt5_ratio\"] = data.apply(lambda x: avoid_zero_division(x, \"pay_amt5\", \"bill_amt5\"), axis=1)\n",
    "            data[\"pay_amt6_bill_amt6_ratio\"] = data.apply(lambda x: avoid_zero_division(x, \"pay_amt6\", \"bill_amt6\"), axis=1)\n",
    "        \n",
    "        if self._calculate_num_negative_bill_statements:\n",
    "            bill_amt_cols = [\"bill_amt1\", \"bill_amt2\", \"bill_amt3\", \"bill_amt4\", \"bill_amt5\", \"bill_amt6\"]\n",
    "            data[\"num_overpays\"] = (data[bill_amt_cols] < 0).sum(axis=1)\n",
    "        \n",
    "        if self._calculate_payment_delays:\n",
    "            data[\"payment_delay_amt1\"] = (data.bill_amt1 - data.pay_amt1).apply(lambda x: max(0, x))\n",
    "            data[\"payment_delay_amt2\"] = (data.bill_amt2 - data.pay_amt2).apply(lambda x: max(0, x))\n",
    "            data[\"payment_delay_amt3\"] = (data.bill_amt3 - data.pay_amt3).apply(lambda x: max(0, x))\n",
    "            data[\"payment_delay_amt4\"] = (data.bill_amt4 - data.pay_amt4).apply(lambda x: max(0, x))\n",
    "            data[\"payment_delay_amt5\"] = (data.bill_amt5 - data.pay_amt5).apply(lambda x: max(0, x))\n",
    "            data[\"payment_delay_amt6\"] = (data.bill_amt6 - data.pay_amt6).apply(lambda x: max(0, x))\n",
    "        \n",
    "        if self._calculate_payment_change_rate:\n",
    "            data[\"payment_change_rate_amt1_amt2\"] = data.apply(lambda x: calculate_change_rate(x, \"pay_amt1\", \"pay_amt2\"), axis=1)\n",
    "            data[\"payment_change_rate_amt2_amt3\"] = data.apply(lambda x: calculate_change_rate(x, \"pay_amt2\", \"pay_amt3\"), axis=1)\n",
    "            data[\"payment_change_rate_amt3_amt4\"] = data.apply(lambda x: calculate_change_rate(x, \"pay_amt3\", \"pay_amt4\"), axis=1)\n",
    "            data[\"payment_change_rate_amt4_amt5\"] = data.apply(lambda x: calculate_change_rate(x, \"pay_amt4\", \"pay_amt5\"), axis=1)\n",
    "            data[\"payment_change_rate_amt5_amt6\"] = data.apply(lambda x: calculate_change_rate(x, \"pay_amt5\", \"pay_amt6\"), axis=1)\n",
    "        \n",
    "        if self._calculate_bill_change_rate:\n",
    "            data[\"bill_change_rate_amt1_amt2\"] = data.apply(lambda x: calculate_change_rate(x, \"bill_amt1\", \"bill_amt2\"), axis=1)\n",
    "            data[\"bill_change_rate_amt2_amt3\"] = data.apply(lambda x: calculate_change_rate(x, \"bill_amt2\", \"bill_amt3\"), axis=1)\n",
    "            data[\"bill_change_rate_amt3_amt4\"] = data.apply(lambda x: calculate_change_rate(x, \"bill_amt3\", \"bill_amt4\"), axis=1)\n",
    "            data[\"bill_change_rate_amt4_amt5\"] = data.apply(lambda x: calculate_change_rate(x, \"bill_amt4\", \"bill_amt5\"), axis=1)\n",
    "            data[\"bill_change_rate_amt5_amt6\"] = data.apply(lambda x: calculate_change_rate(x, \"bill_amt5\", \"bill_amt6\"), axis=1)\n",
    "        \n",
    "        if self._calculate_total_payment:\n",
    "            pay_amt_cols = [\"pay_amt1\", \"pay_amt2\", \"pay_amt3\", \"pay_amt4\", \"pay_amt5\", \"pay_amt6\"]\n",
    "            data[\"total_payment\"] = (data[pay_amt_cols]).sum(axis=1)\n",
    "        \n",
    "        if self._list_vars_to_drop and len(self._list_vars_to_drop) > 0:\n",
    "            data.drop(self._list_vars_to_drop, axis=1, inplace=True)\n",
    "        \n",
    "        return data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e47e3d",
   "metadata": {},
   "source": [
    "#### Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "38f59154",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer():\n",
    "    \"\"\"\"\"\"\n",
    "    pass  # feature selection should be here (and not in data processor), as well as random search CV!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd5833b",
   "metadata": {},
   "source": [
    "#### Model Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0b257525",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator():\n",
    "    \"\"\"\"\"\"\n",
    "    pass  # classification reports "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e86e777",
   "metadata": {},
   "source": [
    "### Data loading, preprocessing and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3f4b6b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../data/train_data.csv\"\n",
    "test_dir = \"../data/test_data.csv\"\n",
    "\n",
    "bill_amt_cols = [\"bill_amt1\", \"bill_amt2\", \"bill_amt3\", \"bill_amt4\", \"bill_amt5\", \"bill_amt6\"]\n",
    "pay_amt_cols = [\"pay_amt1\", \"pay_amt2\", \"pay_amt3\", \"pay_amt4\", \"pay_amt5\", \"pay_amt6\"]\n",
    "\n",
    "mappings = {\n",
    "    \"education\": {\n",
    "        1: 1, #\"Graduate School\", \n",
    "        2: 2, #\"University\", \n",
    "        3: 3, #\"High School\", \n",
    "        4: 4, #\"Others\",\n",
    "        5: 4, #\"Unknown\",\n",
    "        6: 4, #\"Unknown\"     \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a666f629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: 19200 samples, with the target classes as follow:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    18691\n",
       "1     5309\n",
       "Name: target, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val dataset: 4800 samples, with the target classes as follow:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    3738\n",
       "1    1062\n",
       "Name: target, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset: 6000 samples, with the target classes as follow:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    4673\n",
       "1    1327\n",
       "Name: target, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'sample'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7240\\4015218458.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mdata_processor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstandardize_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mdata_processor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'sample'"
     ]
    }
   ],
   "source": [
    "data_processor = DataProcessor(\n",
    "    mappings=mappings\n",
    ")\n",
    "\n",
    "# Load train and test data:\n",
    "data_processor.load_train_data(train_dir)\n",
    "data_processor.load_test_data(test_dir)\n",
    "\n",
    "# Split train into train and val datasets:\n",
    "data_processor.split_data()\n",
    "\n",
    "# Deal with categorical variables:\n",
    "data_processor.treat_categorical_variables(drop_original_vars=True)\n",
    "\n",
    "# Check datasets composition:\n",
    "data_processor.print_dataset_stats()\n",
    "\n",
    "# Perform feature engineering:\n",
    "data_processor.feature_engineering(\n",
    "    calculate_bill_to_limit_bal_ratio=True,\n",
    "    calculate_pay_to_bill_ratio=True,\n",
    "    calculate_num_negative_bill_statements=True,\n",
    "    calculate_payment_delays=True,\n",
    "    calculate_payment_change_rate=True,\n",
    "    calculate_bill_change_rate=True,\n",
    "    calculate_total_payment=True,\n",
    "    list_vars_to_drop=None\n",
    ")\n",
    "\n",
    "# Deal with outliers:\n",
    "data_processor.treat_outliers() # TODO: implement\n",
    "\n",
    "# Apply smote to oversample the minority class:\n",
    "data_processor.perform_oversampling() # TODO: implement\n",
    "\n",
    "# Standardize data:\n",
    "# data_processor.standardize_data()\n",
    "\n",
    "data_processor.X_train.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495ac09a",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "be18ff6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09916111,  0.21860313,  0.60424911, ...,  0.94317227,\n",
       "         0.96657501, -0.09379415],\n",
       "       [-0.9030341 ,  1.57270063, -1.13841718, ..., -0.42527236,\n",
       "        -0.35872959,  0.25168828],\n",
       "       [-1.13430992,  1.57270063,  0.49533247, ..., -0.44909367,\n",
       "        -0.6464422 , -0.30432708],\n",
       "       ...,\n",
       "       [ 0.48462081, -1.13549437, -0.7027506 , ...,  0.31565163,\n",
       "         0.06756384,  0.48903852],\n",
       "       [ 1.48681603,  0.21860313,  0.38641583, ..., -0.65778231,\n",
       "        -0.64642532, -0.51427384],\n",
       "       [ 0.87008051, -1.13549437, -0.59383396, ..., -0.65778231,\n",
       "        -0.64642532, -0.51427384]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_processor.X_val\n",
    "\n",
    "# data_processor.print_datasets_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b177e30f",
   "metadata": {},
   "source": [
    "### Models training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c452907c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0fdd745",
   "metadata": {},
   "source": [
    "### Models evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182c156e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f78553ab",
   "metadata": {},
   "source": [
    "### Conclusions and next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806287b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
